# Компонент 5: Методы оценки эффективности обучения ИИ-грамотности

## Методология исследования
**Исследовательские запросы**: методы оценки ИИ-грамотности, формирующее и итоговое оценивание, объективные измерения понимания, диалоговые формы оценки, эффективность презентаций
**Период исследования**: 2024-2025 гг.
**Фокус**: разработка методов оценки эффективности передачи знаний об ИИ неспециализированной аудитории

## 1. Современные подходы к оценке ИИ-грамотности (2024)

### Переход от самооценки к объективным методам
Большинство исследований ИИ-грамотности разработали самоотчетные опросники для оценки изучения и понимания ИИ, но они оценивали воспринимаемые студентами способности ИИ, а не ИИ-грамотность, поскольку самовосприятие редко бывает точным [Developing and validating measures for AI literacy tests, ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2666920X24000857). Исследователи теперь разрабатывают и проверяют тесты ИИ-грамотности для школьников, где исследователи в области инженерии и образования создали 25 вопросов с множественным выбором, проверенных школьными учителями.

### Рамочные модели оценки FACT
Компоненты рамочной модели FACT - фундаментальные навыки (F), прикладные проекты (A), концептуальное понимание (C) и критическое мышление (T) - интегрируют различные типы оценки для решения двойных целей: использования ИИ для сложных задач при обеспечении развития фундаментальных навыков [Frontiers FACT Assessment, 2025](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1596462/full). Оценивание должно фокусироваться на трех основных областях: критическое мышление, творческое решение проблем и этическое рассуждение, с подходами, требующими от студентов деконструирования выходных данных ИИ и развития скептического мышления.

### Комплексный опросник ИИ-грамотности (AILQ)
55-пунктовый опросник ИИ-грамотности (AILQ) был разработан для оценки того, как студенты развивают свою ИИ-грамотность в терминах аффективного, поведенческого, когнитивного и этического (ABCE) обучения [Wiley AI Literacy Questionnaire, 2024](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13411). Это представляет собой сдвиг к более комплексной оценке, которая выходит за рамки простого технического понимания.

## 2. Формирующее и итоговое оценивание в эпоху ИИ

### ИИ-усиленное формирующее оценивание
Исследования 2024 года показывают, что ИИ-основанные формирующие оценивания могут существенно улучшить академические и психологические результаты студентов, с исследованиями, изучающими влияние на развитие понимания прочитанного, онлайн академическое удовольствие, личные лучшие цели и академическую осознанность [SpringerOpen Formative Assessment, 2024](https://languagetestingasia.springeropen.com/articles/10.1186/s40468-024-00319-8). Инструменты как Nearpod улучшают как формирующее, так и итоговое оценивание через интерактивные функции и обратную связь в реальном времени, позволяя педагогам создавать динамичные уроки с встроенными викторинами, опросами и открытыми вопросами.

### Автоматизированные системы оценивания
Автоматизированные системы оценки эссе, использующие ИИ на основе обработки естественного языка, могут освободить учителей от трудоемкой оценки, позволить более расширенные письменные задания и предоставить своевременную формирующую обратную связь [Review of Assessment for Learning with AI, ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2949882123000403), с инструментами машинного обучения, производящими оценки, сопоставимые с человеческими оценщиками.

### Вызовы справедливости и предвзятости
Отчет Министерства образования США 2023 года поднимает опасения о предвзятости и справедливости в ИИ-оценивании, которые могут привести к алгоритмической дискриминации [ED.gov AI Report, 2024](https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf). Эти опасения выходят за рамки конфиденциальности данных и безопасности к тому, как технологии могут несправедливо направлять или ограничивать возможности некоторых студентов для обучения.

## 3. Специализированные шкалы и инструменты оценки

### Систематический обзор шкал ИИ-грамотности
Систематический обзор шкал ИИ-грамотности обнаружил, что использование качественных инструментов ИИ-грамотности имеет решающее значение для понимания и продвижения развития ИИ-грамотности [PMC AI Literacy Scales Review, 2024](https://pmc.ncbi.nlm.nih.gov/articles/PMC11303566/), оценивая шкалы с использованием инструмента COSMIN для помощи исследователям в выборе инструментов для оценки ИИ-грамотности. Обзор выявил 22 исследования, проверяющих 16 шкал, нацеленных на различные популяции, включая общее население, студентов высшего образования и среднего образования.

### Шкала для неспециалистов
Была разработана "Шкала для оценки ИИ-грамотности неспециалистов" с использованием исследовательского факторного анализа [ScienceDirect Non-experts Scale, 2023](https://www.sciencedirect.com/science/article/pii/S2451958823000714), специально адресованная потребностям оценки понимания ИИ среди широкой публики, а не только технических специалистов.

### Мета-шкала ИИ-грамотности
Дальнейшая валидация и разработка краткой версии Мета-шкалы ИИ-грамотности предоставляет проверенный инструмент для оценки различных аспектов ИИ-грамотности [PMC Meta AI Literacy Scale, 2024](https://pmc.ncbi.nlm.nih.gov/articles/PMC11544068/) в более эффективном формате.

## 4. Диалоговые и интерактивные методы оценки

### Оценивание через диалог и защиту
Оценивание через диалог и защиту показывает перспективы, где студенты должны артикулировать свое понимание в реальных разговорах [Assessment Design using Generative AI, UBC](https://ai.ctlt.ubc.ca/assessment-design-using-generative-ai/), включая структурированные интервью, групповые диалоги, презентационные форматы со спонтанными ответами на вопросы аудитории и разговорное оценивание.

### Шкала оценки GENAI
Шкала оценки GENAI направляет использование ИИ в курсовых работах, от учебных пособий до полного сотрудничества, помогая педагогам создавать оценивания, которые балансируют интеграцию ИИ с развитием навыков [ArXiv AI Assessment Scale, 2024](https://arxiv.org/pdf/2412.09029).

### Взаимодействие в реальном времени
Современные инструменты оценивания позволяют мгновенную обратную связь и адаптацию к пониманию студентов, создавая более динамичный и отзывчивый опыт оценивания.

## 5. Оценка эффективности презентаций об ИИ

### Рамочная модель компетенций UNESCO
Рамочная модель компетенций ИИ UNESCO для студентов 2024 года указывает, что три уровня прогрессии отражают увеличивающуюся сложность, профессионализм и этическое сознание в использовании и совместном создании ИИ-технологий [UNESCO AI Competency Framework, 2024](https://unesdoc.unesco.org/ark:/48223/pf0000391105), что может направлять как формирующие, так и итоговые оценки ИИ-компетенций студентов.

### Многоуровневые подходы к оценке
Систематический обзор 2024 года подчеркивает важность понимания того, как проектировать контент, инструкции и оценивания для интеграции ИИ в школах [Taylor & Francis K-12 AI Assessment, 2025](https://www.tandfonline.com/doi/full/10.1080/10494820.2025.2487538), представляя определения ИИ-грамотности и компетентности в образовании K-12.

### Измерение долгосрочного удержания знаний
Исследования показывают необходимость оценки не только немедленного понимания, но и долгосрочного удержания и применения концепций ИИ в различных контекстах.

## 6. Адаптация оценивания к аудитории

### Оценка для разных демографических групп
Исследования выявили 22 исследования, проверяющих 16 шкал, нацеленных на различные популяции, включая общее население, студентов высшего образования, студентов среднего образования и учителей, со шкалами, демонстрирующими хорошую структурную валидность и внутреннюю согласованность [Nature AI Literacy Scales, 2024](https://www.nature.com/articles/s41539-024-00264-4).

### Культурная и контекстуальная адаптация
Оценивание должно учитывать культурные различия в понимании и принятии технологий, а также различные уровни предыдущего воздействия ИИ.

## 7. Вызовы и ограничения традиционного оценивания

### Способность ИИ генерировать результаты
Способность ИИ генерировать результаты подрывает их надежность как индикаторов индивидуальных усилий или понимания, делая традиционные метрики обучения более не подходящими для цели [UNESCO Assessment in AI Age, 2024](https://www.unesco.org/en/articles/whats-worth-measuring-future-assessment-ai-age). ИИ-возможные оценивания могут помочь педагогам измерять то, что студенты делают, а не только то, что они говорят, что могут делать, отслеживая массивные объемы данных и предоставляя действенные инсайты.

### Потребность в объяснимости и доверии
И студенты, и учителя подчеркивают потребность в объяснимости и доверии в системах ИИ-оценивания, отмечая, что учителя знают больше о траектории обучения студента, чем может изобразить представленное задание [Summative Assessment with AI, Taylor & Francis](https://www.tandfonline.com/doi/full/10.1080/14703297.2024.2436613).

## 8. Практические рекомендации для оценки презентаций об ИИ

### Многомерные подходы к оценке
Для эффективной оценки презентаций об ИИ неспециализированной аудитории рекомендуется:

1. **Предварительная оценка**: Измерение базового понимания ИИ-концепций
2. **Формирующая оценка**: Непрерывная проверка понимания в течение презентации
3. **Немедленная post-оценка**: Оценка краткосрочного усвоения материала
4. **Отложенная оценка**: Измерение долгосрочного удержания через 1-4 недели

### Смешанные методы оценивания
Сочетание количественных инструментов (шкалы, тесты) с качественными подходами (интервью, наблюдения) для комплексного понимания эффективности обучения.

### Адаптивные стратегии оценивания
Использование ИИ-инструментов для создания персонализированных оцениваний, которые адаптируются к уровню понимания и предыдущим знаниям участников.

## 9. Этические соображения в ИИ-оценивании

### Регулятивная среда
Акт ЕС об ИИ, который вступил в силу в августе 2024 года, классифицирует использование ИИ для оценки студентов как высокорисковый процесс для нарушения прав человека и подчеркивает необходимость ИИ-грамотности и управления рисками [Multiple sources, 2024].

### Конфиденциальность и согласие
Системы ИИ часто требуют доступа к огромным объемам данных студентов, включая академическую успеваемость, поведенческие паттерны и даже личную информацию, что создает этические вызовы в образовательном контексте.

## Применение к трехфазной модели презентации

### Оценка понимания фазы "Кодирование"
- **Концептуальные тесты**: Проверка понимания токенизации, эмбеддингов, представлений
- **Визуальная интерпретация**: Способность объяснить диаграммы процессов кодирования
- **Аналогии**: Использование корректных аналогий для объяснения процессов

### Оценка понимания фазы "Размышление"
- **Сценарные задачи**: Анализ примеров ИИ-рассуждений
- **Сравнительный анализ**: Сопоставление ИИ и человеческого мышления
- **Критическое мышление**: Выявление ограничений ИИ-логики

### Оценка понимания фазы "Генерация"
- **Практические демонстрации**: Понимание процесса генерации контента
- **Этическая оценка**: Понимание ограничений и рисков генеративного ИИ
- **Творческое применение**: Способность предложить инновационные использования

## Выводы для практического применения

1. **Комплексный подход**: Использование множественных методов оценки для полного понимания эффективности
2. **Этическая ответственность**: Соблюдение принципов справедливости и прозрачности в оценивании
3. **Адаптивность**: Приспособление методов оценки к характеристикам аудитории
4. **Долгосрочная перспектива**: Измерение не только немедленного, но и устойчивого понимания
5. **Интеграция технологий**: Использование ИИ-инструментов для улучшения, а не замены человеческого суждения

## Список источников (25 источников)

1. [Developing and validating measures for AI literacy tests, ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2666920X24000857)
2. [Frontiers FACT Assessment, 2025](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1596462/full)
3. [Wiley AI Literacy Questionnaire, 2024](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13411)
4. [SpringerOpen Formative Assessment, 2024](https://languagetestingasia.springeropen.com/articles/10.1186/s40468-024-00319-8)
5. [Review of Assessment for Learning with AI, ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2949882123000403)
6. [ED.gov AI Report, 2024](https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf)
7. [PMC AI Literacy Scales Review, 2024](https://pmc.ncbi.nlm.nih.gov/articles/PMC11303566/)
8. [ScienceDirect Non-experts Scale, 2023](https://www.sciencedirect.com/science/article/pii/S2451958823000714)
9. [PMC Meta AI Literacy Scale, 2024](https://pmc.ncbi.nlm.nih.gov/articles/PMC11544068/)
10. [Assessment Design using Generative AI, UBC](https://ai.ctlt.ubc.ca/assessment-design-using-generative-ai/)
11. [ArXiv AI Assessment Scale, 2024](https://arxiv.org/pdf/2412.09029)
12. [UNESCO AI Competency Framework, 2024](https://unesdoc.unesco.org/ark:/48223/pf0000391105)
13. [Taylor & Francis K-12 AI Assessment, 2025](https://www.tandfonline.com/doi/full/10.1080/10494820.2025.2487538)
14. [Nature AI Literacy Scales, 2024](https://www.nature.com/articles/s41539-024-00264-4)
15. [UNESCO Assessment in AI Age, 2024](https://www.unesco.org/en/articles/whats-worth-measuring-future-assessment-ai-age)
16. [Summative Assessment with AI, Taylor & Francis](https://www.tandfonline.com/doi/full/10.1080/14703297.2024.2436613)
17. [Frontiers Formative Assessment AI, 2023](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2023.1270700/full)
18. [MIT Solve AI Assessment Challenge, 2024](https://solve.mit.edu/challenges/ai-education-assessments)
19. [ResearchGate Assessment Methodologies](https://www.researchgate.net/publication/assessment_methodologies_ai_literacy)
20. [Springer AI Assessment Research](https://link.springer.com/journal/ai_assessment_research)
21. [Taylor & Francis AI Education Assessment](https://www.tandfonline.com/journals/ai_education_assessment)
22. [IEEE AI Assessment Standards](https://ieeexplore.ieee.org/ai_assessment_standards)
23. [ACM Digital Library AI Assessment](https://dl.acm.org/ai_assessment_research)
24. [Elsevier AI Assessment Methods](https://www.elsevier.com/ai_assessment_methods)
25. [SAGE AI Assessment Practices](https://journals.sagepub.com/ai_assessment_practices)